# BUILD AND LOAD CUSTOM IMAGES INTO MINIKUBE:
# cd /home/rnebot/GoogleDrive/AA_OpenDx28/3dslicerhub
# docker build -t opendx/tslicerh .
## cd proxy
## docker build -t opendx/nginx .
#
# BASE and SLICER
# docker build -t opendx/vnc-base https://github.com/OpenDx28/docker-vnc-base.git#:src
# docker build -t opendx/slicer --build-arg BASE_IMAGE="opendx/vnc-base:latest" https://github.com/OpenDx28/docker-slicer.git#:src
#
# STACKOVERFLOW: https://stackoverflow.com/questions/42564058/how-to-use-local-docker-images-with-minikube
#
#
# minikube image load opendx/slicer
# minikube image load opendx/tslicerh
# minikube image load opendx/nginx
#
#
# RBAC to allow 3dslicer hub execute "kubectl"
# https://itnext.io/running-kubectl-commands-from-within-a-pod-b303e8176088
#
# BASH in a container, in the POD:
# kubectl exec -ti proxy-shub -c 3dslicer-hub -- bash
# kubectl exec -ti proxy-shub -c nginx-container -- bash

apiVersion: v1
kind: ServiceAccount
metadata:
  name: internal-kubectl
---
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: modify-pods
rules:
  - apiGroups: ["", "metrics.k8s.io"]
    resources:
      - pods
      - pods/exec
    verbs:
      - get
      - create
      - list
      - delete
  - apiGroups: ["apps"]
    resources:
      - deployments
    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
  - apiGroups: ["apps"]
    resources:
      - deployments/scale
    verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: modify-pods-to-sa
subjects:
  - kind: ServiceAccount
    name: internal-kubectl
roleRef:
  kind: Role
  name: modify-pods
  apiGroup: rbac.authorization.k8s.io
---
# POD with 3dslicer-hub and nginx to redirect to the different 3dslicer hub containers
# - it initializes an empty nginx.conf file in a volumeMount (temporary fs to share files between containers of the POD)
apiVersion: v1
kind: Pod
metadata:
  name: proxy-shub
  labels:
    app: shub
    # Label used by get_container_ip. The value is defined in "env" with TDSLICERHUB_NAME variable
    app-user: tdslicerhub-3dslicer-hub
spec:
  # Force master-node (TEIDE HPC)
  nodeName: opendx2
  serviceAccountName: internal-kubectl
  restartPolicy: OnFailure
  volumes:
    - name: nginx-conf
      emptyDir: {}
  initContainers:
    - name: init-nginx-conf
      image: busybox:latest
      imagePullPolicy: IfNotPresent
      command: [ "/bin/sh", "-c", "mkdir -p /etc/nginx/conf.d && echo events { } http { } > /etc/nginx/nginx.conf && cp /etc/nginx/nginx.conf /etc/nginx/conf.d/default.conf"]
      volumeMounts:
      - name: nginx-conf
        mountPath: /etc/nginx
  containers:
    - name: 3dslicer-hub
      image: localhost:5000/opendx28/tslicerh:latest
      imagePullPolicy: Always
      ports:
      - containerPort: 8080
      volumeMounts:
        - mountPath: /app/proxy
          name: nginx-conf
    - name: nginx-container
      resources:
        requests:
          memory: "64Mi"
          cpu: "250m"
        limits:
          memory: "128Mi"
          cpu: "500m"
      image: nginx:latest
      imagePullPolicy: Always
      ports:
      - containerPort: 80
      volumeMounts:
        - mountPath: /etc/nginx
          name: nginx-conf

#---
#apiVersion: v1
#kind: PersistentVolume
#metadata:
#  name: nfs-pv
#spec:
#  capacity:
#    storage: 10Gi
#  accessModes:
#    - ReadWriteMany
#  persistentVolumeReclaimPolicy: Retain
#  nfs:
#    # TODO Change to the path and host name (as seen by k8s master)
#    path:
#    server:


---
# Cluster service for proxy-shub pod. This Cluster svc will be not accessible from outside it is ment to be reached
#  internally by ingress
apiVersion: v1
kind: Service
metadata:
  name: shub-svc-cluster
spec:
  selector:
    app: shub
  ports:
    - protocol: TCP
      port: 80

---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-shub
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt"
spec:
  tls:
  - hosts:
    - 3dslicerhub.medtec4susdev.org
    secretName: myapp-cert
  ingressClassName: traefik
  rules:
    - host: 3dslicerhub.medtec4susdev.org
      http:
        paths:
        - path: /
          pathType: Prefix
          backend:
            service:
              name: shub-svc-cluster
              port:
                number: 80
                
---
# ldap deplyment manifest

apiVersion: apps/v1
kind: Deployment
metadata:
  name: ldap-deployment
  labels:
    app: ldap
spec:
  replicas: 1
  selector:
    matchLabels:
      app: ldap
  template:
    metadata:
      labels:
        app: ldap
    spec:
      containers:
        - name: ldap
          image: osixia/openldap:stable
          args: ["--copy-service", "--loglevel","debug"]
          env:
            - name: LDAP_ADMIN_PASSWORD
              value: "admin_pass"
            - name: LDAP_DOMAIN
              value: "opendx.org"
            - name: LDAP_ORGANISATION
              value: "opendx"
            - name: LDAP_TLS_VERIFY_CLIENT
              value: "allow"
          volumeMounts:
            - name: ldap-data
              mountPath: /var/lib/ldap
            - name: ldap-config
              mountPath: /etc/ldap/slapd.d
            - name: ldap-certs
              mountPath: /container/service/slapd/assets/certs
            - name: container-run
              mountPath: /container/run
            - name: ldap-users
              mountPath: /home/users
          ports:
            - containerPort: 389
              name: openldap
            - containerPort: 636
              name: openldapssl
      volumes:
      - hostPath:
          path: /mnt/opendx28/ldap/data/slapd/database
          type: ""
        name: ldap-data
      - hostPath:
          path: /mnt/opendx28/ldap/data/slapd/config
          type: ""
        name: ldap-config
      - hostPath:
          path: /mnt/opendx28/ldap/users
          type: ""
        name: ldap-users
      - hostPath: # esto deber√≠a ser un secret
          path: /mnt/opendx28/ldap/certs
          type: ""
        name: ldap-certs
      - name: container-run
        emptyDir: {}



---
# ldap cluster

apiVersion: v1
kind: Service
metadata:
  name: tdslicerhub-openldap
spec:
  selector:
    app: ldap
  ports:
    - protocol: TCP
      port: 389
  type: ClusterIP